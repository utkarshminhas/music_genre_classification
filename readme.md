Workflow of the whole project
- installed linux, cuda
- identify how many genres are there and draw a line somewhere because there are a lot of genres and subgenres out there
- grab some spotify playlists which represent classic genres
- get spotify api credentials by registering from their website
- FILE 1
    - filename - 1_create_spotify_df.py
    - ping their api with the playlists link you have saved to get the individual details of each song. 
    - Label these songs since you know what playlist each songs belong to. 
    - Export to pandas dataframe
- NOTEBOOK 2
    - filename - 2_EDA_songs.ipynb
    - Do some EDA on the dataset in a jupyter notebook
        - Process and clean the dataset
            - Export the processed and cleaned dataset so that i can be used in the next stage 
        - do some visualizations to get a better idea of the dataset
- FILE 3
    - filename - 3_download_songs.py
    - Using the spotdl or some other library, download the spotify songs with the help of the cleaned dataset
        - the script might run for a long time since a llot of songs are being downlaoded
- FILE 4
    - fileame - 4_process_songs.py
    - create a script which will load the downloaded songs into "n" seconds increments and use librosa to extract either mfcc features or mel spectograms from those "n" second snippets which can be used as features/training data for the CNN model or some other classical ML approach/techniques

- FILE 5
    - filename - 5_cnn_model.py
    - A file to easily load the dataset/images
        - (how to split into train,test datasets)[https://www.tensorflow.org/tutorials/load_data/images#train_a_model]
    - clean and preprocess the images, convert to correct format and specifications 
    - make it so that they can directly be used as model input for the dataloader
    - load the dataset for training
        - train test split,dataloaders, etc. 
    - define model architecture
        - hyperparams
    - train the model
        - save best model, checkpoint
    - evaluation metrics, 
        - rough measure of metrics on test set
- FILE 6
    - make 2 functions
        - one to run inference on a song
            - since songs are > 30s, chunk them, run inference separately and parallely, if possible(maybe use batch processing and pipeline???)
            - select output by mode (most frequently predicted genre throughout chunks), sort of like ensemble learning
        - one to run inference on a said playlist ??? (optional)
- FILE 7
    - extend and API for function number 1 in FILE 8 

# what about baseline mode using GTZAN? 
- think about it later
- because:
    - the labels in GTZAN are going to lesser than the ones I have, my porposed dataset and the model are going to be more up to date, at least with the current songs
    - ensemble learning already happening throughout chunks, adding a new/second model for ensemble output gen would add too many chunks,  would be a nightmare in terms of processing speed
    - data processing might be different

